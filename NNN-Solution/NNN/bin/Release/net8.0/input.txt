During the research process, search engines such as Google have traditionally served as a primary source for finding information. However, these can be both slow and tedious, with many students opting to focus on finding a direct answer to a given problem rather than using critical thinking to develop an answer from a variety of information. On the other hand, LLM’s, such as ChatGPT, can both quickly summarize large amounts of information, and provide various views and/or solutions regarding a topic or problem. This indicates a clear advantage over the single perspective which students often obtain from search engines, with LLM’s giving access to far more robust information including multiple perspectives. As a result of LLM responses containing a variety of viewpoints, students are forced to analyse each perspective in order to find those which carry value regarding the original question or problem, developing better critical thinking skills in the process. Therefore, the use of LLM’s to find answers and solutions generally has a greater positive impact on critical thinking skills compared to the use of traditional search engines. The fact that LLM’s are beneficial to critical thinking was further demonstrated through a study, which examined the impact of students using ChatGPT in place of Google. The study focused on 93 11th grade students from Taiwan, taking the same class about the United Nations’ Sustainable Development Goals, who were divided into a control group of 47 and an experimental group of 46. The control group was required to conduct all of their research using the Google search engine while the experimental group used ChatGPT to source information and help develop potential sustainable solutions. The impacts of both methods were analysed using both a critical thinking questionnaire with a 1-5 Likert scale and an interview. Thus, both quantitative and qualitative data were collected, providing greater insight into how the students in each group were affected. As such, the results can be accepted as relatively representative of the benefits and/or drawbacks of the use of ChatGPT for research and brainstorming purposes. The results of the study largely supported the idea of LLM’s benefitting critical thinking. On the critical thinking questionnaire, the experimental group showed a mean score of 4.32 compared to the control group’s 4.00. Therefore, the use of ChatGPT, and by extension LLM’s as a whole, results in a noticeable enhancement in the critical thinking skills of students. This is further supported by the fact that improved critical thinking skills resulting from the course were mentioned in the interview by 7 students from the experimental group while only 2 did so from the control group. Although only explicitly mentioned by a small portion of the students, significantly more students from the experimental group saw a benefit to their critical thinking, indicating that ChatGPT promoted such skills more than the Google search engine. Nonetheless, certain drawbacks to the use of ChatGPT were also discovered. Students were able to simply accept answers from the LLM without thinking critically about the information, with multiple admitting to plagiarizing ChatGPT during the interview. In such a situation, the use of LLM’s would in fact potentially inhibit critical thinking through eliminating any need for the student to exercise such skills. However, the functionality of LLM’s in itself also counters this detrimental effect. As discussed previously, LLM’s are able to provide a variety of viewpoints and potential answers. Therefore, it would prove difficult for a student to simply accept the LLM’s answer due there being multiple different options. The student would be forced to think critically about all of the provided answers in order to determine which is most accurate and/or best suited for their specific situation. Thus, due to their presentation of varied views, LLM’s largely promote critical thinking skills when used during the research process in place of traditional search engines. Despite the clear benefits of LLM use for critical thinking skills within structured environments, the same is not necessarily true when students use such tools fully independently. A study used a survey to determine the impact of the use of ChatGPT on 61 undergraduate students at Caldwell University. Due to the qualitative nature of the study as well as the fact that the data were based solely on the personal views of the students surveyed, the results cannot be used as definitive evidence of the impact of LLM’s on critical thinking. Nonetheless, the study still provides insight into how students may be affected. To begin with, it was found that around 60% of students used ChatGPT to solve complicated problems while roughly 55% found that ChatGPT assisted them in understanding new information. Such findings may indicate that the use of LLM’s does in fact promote critical thinking skills, primarily due to the fact that the tools allowed students to gain a deeper understanding of information which they may have otherwise struggled to understand. Since critical thinking involves in-depth analysis of evidence and therefore requires a high level of understanding of information related to the topic, the increased understanding gained from the use of LLM’s would enable greater critical thinking. As such, LLM’s can once again be seen to benefit students’ critical thinking skills. However, other results from the study’s survey suggest that LLM’s may also have a negative effect on critical thinking. It was found that roughly 50% of students surveyed considered themselves to be dependent on ChatGPT in order to complete their schoolwork, with many also commenting that they found themselves thinking less deeply about problems due to the tool simply providing them with the correct answer. As such, the concern identified in the study, that of students simply accepting the answers provided by the LLM, arises once again. Unlike in the structured environment of the study, there is no guarantee in this case that the tool provided students with more than a single perspective and/or answer which could otherwise lessen the impact as explained previously. Thus, there is a possibility that, when used independently by students, LLM’s may prove detrimental to critical thinking skills via encouraging students to accept answers without applying any such skills. Finally, an interesting effect emerges from the possibility of LLM’s providing incorrect information. Although such tools are generally viewed as relatively accurate, LLM’s have the potential to answer using inaccurate information. This encourages students to apply critical thinking skills to any replies which LLM’s provide them with in order to ensure that they are not falling victim to misinformation. Through being required to perform such analysis while using these tools, students would gradually improve their critical thinking abilities. However, for this to occur, students must first recognize the fact that it is necessary to critically evaluate the responses provided by LLM’s. Two results from the study thus stand out: roughly 65% of surveyed students trust ChatGPT to at least a medium extent while around 33% rarely verified the information which the tool provided. Although the percentage of students who trust the output of ChatGPT appears quite large, only a fraction of these students fully believe what the LLM replies with. Additionally, it is evident that the majority of students verify the information which ChatGPT provides, suggesting that they recognize the need to apply critical thinking when using LLM’s. Nonetheless, the percentage of students who do not apply any critical thinking skills during their use of LLM’s, and therefore do not gain any improvement in their critical thinking abilities, is still significant. As such, at least based on the results of the study, roughly 33% of students will receive a detrimental effect to their critical thinking skills as a result of their use of LLM’s. However, for the majority of students LLM’s will still prove to be beneficial to their critical thinking abilities due to encouraging them to repeatedly exercise such skills during the use of the given tools. In addition to the already discussed advantages of LLM’s, they possess yet more strengths, both when considering the previous comparison to traditional search engines and in the context of completely unique roles. A key characteristic of tools such as ChatGPT is their ability to answer followup questions which directly draw upon previous discussion. As a result, through providing an easy means of inquiring about the specifics of a topic, they allow students to engage far more deeply with the information which they have used the LLM to procure. Given the fact that critical thinking is in itself an in-depth analysis of evidence and options, LLM’s directly encourage students to practice their critical thinking skills during their research processes. Such practice, which is simply not provided by traditional search engines, in turn improves the students’ critical thinking abilities. Additionally, LLM’s can also provide for personalized learning tailored to the needs of each individual student. As such, every student can receive the support which they themselves need, improving their individual learning experience. When applied to the acquisition of critical thinking skills therefore, the use of LLM’s can prove highly beneficial to students’ improvement of said skills. A study in Ghana focused on how these traits of LLM’s improved 125 undergraduate students’ critical thinking skills. The students, who were all taking the same 12 week Quantitative Research Design course, were divided into a control group of 65 students and an experimental group of 60 students. Both groups were provided with prompts prior to each lecture, with the experimental group using ChatGPT to help answer the questions while the control group was required to use traditional research methods such as search engines. Additionally, the experimental group was allowed to, if necessary, use ChatGPT to clarify information during and after each lecture. These methods directly demonstrate the use of LLM’s to examine information in greater depth along with each student being able to use the tool to complement their learning in whichever way they find assists them the most. The study used a 1-5 Likert scale-style Critical Thinking Scale administered to all participants in order to determine the impact on each group’s critical thinking skills. The scale was initially given to all students as a pretest prior to the beginning of the course and then again as a posttest after 3 weeks of taking the course. Additionally, an interview was conducted at the same time as the posttest in order to collect qualitative data from the students. The results of the study showed a noticeable difference in the critical thinking scores of the experimental and control groups. The control group achieved mean scores of 24.9 and 30.6 on the pretest and posttest respectively. Meanwhile, the experimental group mean scores were 28.4 and 39.2 respectively. As such, the control group’s mean score increased by 5.7 while the experimental group showed an increase of 10.8. It is therefore evident that the use of ChatGPT as a personalized aid in the learning process improved students’ acquisition of critical thinking skills. The results of the qualitative data collected by the interview further support the said conclusion. Most students' responses included the view that ChatGPT assisted them in better understanding both the material of the course and how to determine which of the different research methods discussed in the course was applicable in a given situation. Therefore, the use of the LLM significantly improved the depth of the students’ knowledge, which is in turn key to greater critical thinking abilities. Furthermore, the capability of viewing a given situation and based on the circumstances to find the most appropriate research method aligns with the use of critical thinking skills to analyse the available evidence. As such, since the use of LLM’s improved the participants’ ability to find the most appropriate research method, such tools are beneficial to critical thinking. The critical thinking benefits arising from the use of LLM’s become even greater when the discipline in which the said tools are being used is in itself conducive to the acquisition of such skills. One such area is the practice of debugging computer code, a skill involving the resolving of issues within already written code. Effective debugging of code requires a deep understanding of how a given coding language works, as well as of how and why different errors occur. As such, the action of debugging code alone constitutes an exercise in critical thinking. The understanding necessary to successfully debug code can also be obtained with the assistance of LLMs, indicating a potential for their use to benefit critical thinking abilities. Additionally, the process of dialogic learning can also contribute to a greater improvement in critical thinking skills. A key characteristic of LLM tools is their ability to engage in a dialogue with the user, and thus can also serve as a catalyst for dialogic learning. Therefore, through combining the training of debugging skills with dialogic learning, LLM’s can produce a great improvement in critical thinking abilities when used for such purposes. The effect of using LLM’s to assist in learning to debug code and as a tool for dialogic learning was examined in a study, which focused on 80 6th grade students. The students were split into a control group and experimental group of 40 students each, with both groups receiving four weeks of debugging training. The control group was given standard instruction by a teacher and used traditional methods of finding and troubleshooting issues using documentation and support from the instructor. On the other hand, the experimental group received additional instruction through an LLM and directly interacted with the tool via dialogue while debugging the code. Therefore, the LLM served as a direct source of dialogic learning for the students in the experimental group as it could facilitate dialogues regarding the debugging process. Quantitative data were collected via a debugging and computational thinking test which was administered prior to, immediately after, and one month after the training. Additionally, qualitative data were gathered through an interview immediately following the conclusion of the training. Computational thinking is predominantly a process of problem solving which involves deep analysis of the problem at hand. The skill is characterized by the division of an issue into its constituent challenges and the assessment of each of these sub-problems. Furthermore, computational thinking considers the precise context of a given problem, while also including the selection of appropriate methods for resolving the problem. Therefore, computational thinking can be considered a subset of critical thinking skills as both involve deep analysis of the various aspects and facets of a given problem. The results gathered by the computational thinking tests administered in the study can thus serve as indicators of the development of critical thinking skills.
Both the quantitative and qualitative results of the study indicated a benefit to critical thinking abilities resulting from the use of LLM’s by the experimental group. The mean scores for the debugging assessments administered to the experimental group prior to, immediately after, and one month after the training were 9.31, 12.9, and 14.0 respectively. In contrast, the control group achieved mean scores of 9.89, 11.8, and 12.0 respectively. Therefore, the experimental group showed an average improvement of 4.69 points compared to the control group’s improvement of only 2.11 points. As such, the use of the LLM resulted in a significantly greater improvement in debugging ability compared to standard methods of teaching debugging. Since debugging inherently requires the use of critical thinking to analyse and consequently resolve issues within code, these results also indicate a benefit to critical thinking skills arising from the use of the tool. A similar pattern emerged within the average scores of the two groups on the computational thinking test. The mean scores for the experimental group on the initial, subsequent, and delayed assessments were 66.2, 70.4, and 78.2 respectively. On the other hand, the control group achieved average scores of 65.7, 67.6, and 69.3 respectively. Thus, the average improvement in the scores of the experimental group was 12.0 while the control group showed a lesser increase of merely 3.6 points. It appears therefore that the use of an LLM during the training process provided a considerably greater benefit to computational thinking skills compared to standard methods. Given that computational thinking falls into the overarching category of critical thinking skills, the results of this assessment also indicate improvements in critical thinking abilities arising from the use of LLM’s. Finally, such a conclusion is also supported by the results collected from the interview. The students in the experimental group reported that the LLM helped them more deeply understand code while also benefitting their problem-solving abilities. Furthermore, the tool also provided deeper insight into errors and debugging and improved the students’ ability to find the source of bugs independently. On the other hand, students within the control group mentioned finding it difficult to expand their ways of thinking in order to solve new types of errors. Once again, there is indication of a connection between the use of LLM’s and greater critical thinking capabilities. The fact that the experimental group showed a greater ability to debug without external assistance points to an improved ability to deeply analyse and understand given problems. In contrast, the control group’s difficulty in tackling new issues shows a lesser capacity for critical thinking due to being unable to assess the given errors deeply enough to find solutions. Therefore, the use of LLM’s can once again be seen to significantly improve critical thinking skills as compared to traditional tools. Of particular note is the ability of LLM’s to engage in direct conversation with users, thus providing the benefits observed with dialogic learning. Such characteristics provide LLM use with a great advantage over traditional methods, including in the development of critical thinking abilities. Despite the various advantages to the use of LLM’s, the way in which such tools have been promoted has a potential to result in a detrimental effect on critical thinking. LLM tools have been heavily advertised as being highly effective for use in schools, both by teachers and students. Of particular note is the idea of LLM’s being used to provide information and writing within the educational environment. This is in itself not an issue since LLM’s have been shown to have a positive impact on critical thinking when used in the learning environment. However, these tools have also been shown to have a number of drawbacks which could result in a negative effect. For instance, due to their nature of essentially behaving in a manner similar to an “autocorrect” through predicting the most likely next word, LLM’s do not inherently understand the underlying meaning of any words. Due to this deficiency, such tools can be prone to providing highly inaccurate information. For instance, Google’s LLM failed to correctly answer questions about the James Webb Space Telescope while being promoted for use in education in 2023. Nonetheless, despite these issues, LLM’s are still being advertised as being sufficiently advanced and accurate to be used as sources of information within education. As such, the promotion of such tools discourages the use of critical thinking skills to deeply analyse and cross reference the information provided by LLM’s through implying a high degree of accuracy despite an apparent lack thereof. Another aspect of LLM advertising could potentially raise the possible issue identified, that of students simply accepting and plagiarizing the responses given by such tools. Specifically, LLM tools have been promoted as having the ability to write work directly for students. Combined with the advertised accuracy of LLM’s, this encourages students to simply use the answers provided by the tools without applying critical thinking to analyse the contained information. Furthermore, students are discouraged from using such skills in the problem-solving process whatsoever, as LLM’s have been promoted as being able perform all of the necessary work and analysis in their place. Finally, LLM’s are also being advertised as aids for teachers, particularly in the area of assessing students’ progress within a topic. Through measuring progress using such tools, the fundamental idea of learning is restricted to being quantifiable by a computer. However, measuring students’ acquisition and development of skills such as critical thinking purely numerically does not provide a comprehensive representation of a student’s abilities. For instance, studies which focused on measuring skills such as critical thinking, used both quantitative and qualitative data, with the latter being collected via an interview. As such, students’ development of such skills could be hindered by the use of LLM’s in education through their abilities being misrepresented and them therefore not receiving the necessary support to further improve critical thinking. When it comes to the question of how the use of LLM’s impacts critical thinking, both positive and negative effects appear present. On one hand, results from studies indicated improvement in the critical thinking abilities of students when LLM’s were used in a relatively controlled and structured environment. On the other hand, studies provided data which suggested issues of students accepting LLM responses without applying any critical thinking, while also in certain cases becoming overreliant on the tools. Yet, LLM’s can also greatly enhance the learning of other skills requiring critical thinking, such as debugging, while also serving as a catalyst for dialogic learning, as evidenced by the results of the study. However, the ways in which LLM’s have been advertised promote reduced critical thinking among students. Despite such drawbacks, it appears that the primary impact of LLM use on critical thinking is largely positive. For instance, students are encouraged to engage more deeply with information and thus gain an improved understanding of the problems at hand. This in turn allows them to better exercise critical thinking skills, while also being able to use LLM’s to acquire various skills which further enhance critical thinking. In comparison, the negative impacts from the use of such tools in unstructured environments seem relatively low. Therefore, LLM’s and their use appear to largely benefit the development of critical thinking skills among users.
